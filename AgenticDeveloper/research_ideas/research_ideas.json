{
  "759cd9df-0859-4749-b634-7b8638fa5881": {
    "description": "The momentum universe shrinkage effect refers to the phenomenon where the performance of momentum strategies changes when the universe of stocks is shrunk or changed.\nThis effect is observed in the KOSPI 200 index in the South Korean stock market.\nThe KOSPI 200 index has two formal subsets: KOSPI 100 and KOSPI 50, which are constructed based on market capitalization and sector diversification.\nThe study tests the momentum effect in the KOSPI 200 and its subuniverses, including KOSPI 100, KOSPI 50, and other implicit subuniverses constructed from these three universes.\nThe momentum strategy is implemented by sorting stocks into ten groups based on their cumulative returns during the estimation period.\nThe loser group (R1) and the winner group (R10) are constructed by buying the best (R10) and short-selling the worst (R1) with the same amount.\nThe portfolio is liquidated after K periods to take profits from the momentum portfolio.\nThe study finds that the momentum returns are not homogeneous in the subsets of the momentum universe.\nThe KOSPI 50 components have a negative effect on the momentum performance.\nThe subuniverses excluding the KOSPI 50 components, such as (200-50), (200-100), and (100-50), outperform the KOSPI 200 and the KOSPI 100.\nThe study suggests that market capitalization and sector diversification are main factors for the momentum effect.\nThe size portfolio, which buys larger market capitalization equities and sells smaller market-cap equities, shows a unique performance.\nThe top 41-100 stocks in market capitalization outperform equities in other size groups.\nThis finding explains the momentum universe shrinkage effect, why non-KOSPI 50 universes beat the pools which include the KOSPI 50 components.\nThe liquidity portfolio, ranked by the fractional volume during the estimation period, shows similar results with the traditional momentum strategies in subuniverses.\nThere is a tendency that performance of the liquidity portfolio becomes weaker when the market universes include the KOSPI 50 members.",
    "edge": "The momentum universe shrinkage effect provides an edge in momentum strategies by identifying the optimal universe of stocks that can generate higher returns.\nThe study highlights the importance of considering market capitalization and sector diversification in constructing the momentum universe.\nThe size portfolio and liquidity portfolio provide additional edges in identifying profitable momentum strategies.",
    "pseudo_code": {
      "signal_generation": "Sort stocks into ten groups based on their cumulative returns during the estimation period. Construct the loser group (R1) and the winner group (R10) by buying the best (R10) and short-selling the worst (R1) with the same amount.",
      "entry_rules": "Enter the position when the momentum portfolio is constructed.",
      "exit_rules": "Liquidate the portfolio after K periods to take profits from the momentum portfolio."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/1211.6517v1",
      "title": "Momentum universe shrinkage effect in price momentum"
    },
    "idea_name": "Momentum Universe Shrinkage Effect",
    "updated_dt": "2025-04-14T12:38:49.207260"
  },
  "dfb3baa5-878a-4998-b58d-f9cb9aefc87c": {
    "description": "The size portfolio is constructed by buying larger market capitalization equities and selling smaller market-cap equities.\nThe study finds that the top 41-100 stocks in market capitalization outperform equities in other size groups.\nThis finding explains the momentum universe shrinkage effect, why non-KOSPI 50 universes beat the pools which include the KOSPI 50 components.\nThe liquidity also works as a predictive factor on the future returns.\nThe liquidity portfolio ranked by the fractional volume during the estimation period shows similar results with the traditional momentum strategies in subuniverses.",
    "edge": "The size portfolio provides an edge in identifying profitable momentum strategies by focusing on the top 41-100 stocks in market capitalization.\nThe liquidity portfolio provides an additional edge in identifying profitable momentum strategies by ranking stocks based on fractional volume.",
    "pseudo_code": {
      "signal_generation": "Sort stocks into ten groups based on their market capitalization. Buy larger market capitalization equities and sell smaller market-cap equities.",
      "entry_rules": "Enter the position when the size portfolio is constructed.",
      "exit_rules": "Liquidate the portfolio after a given holding period."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/1211.6517v1",
      "title": "Momentum universe shrinkage effect in price momentum"
    },
    "idea_name": "Size Portfolio",
    "updated_dt": "2025-04-14T12:38:49.208177"
  },
  "4c50db1c-0847-428c-a151-713cdc30ed65": {
    "description": "The liquidity portfolio is constructed by ranking stocks based on fractional volume during the estimation period.\nThe study finds that the liquidity portfolio shows similar results with the traditional momentum strategies in subuniverses.\nThere is a tendency that performance of the liquidity portfolio becomes weaker when the market universes include the KOSPI 50 members.\nThe liquidity portfolio provides an edge in identifying profitable momentum strategies by focusing on liquid stocks.",
    "edge": "The liquidity portfolio provides an edge in identifying profitable momentum strategies by focusing on liquid stocks.\nThe study highlights the importance of considering liquidity in constructing the momentum universe.",
    "pseudo_code": {
      "signal_generation": "Sort stocks into ten groups based on their fractional volume during the estimation period. Buy the most liquid equities and sell the most illiquid equities.",
      "entry_rules": "Enter the position when the liquidity portfolio is constructed.",
      "exit_rules": "Liquidate the portfolio after a given holding period."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/1211.6517v1",
      "title": "Momentum universe shrinkage effect in price momentum"
    },
    "idea_name": "Liquidity Portfolio",
    "updated_dt": "2025-04-14T12:38:49.208791"
  },
  "67391af1-e874-4c3f-bb29-95a7379c18ac": {
    "description": "The study analyzes the trading patterns of individual, institutional, and foreign investors in the South Korean stock market.\nEach investor group has a different trading pattern and gives diverse market impacts.\nIndividual investors tend to underperform and are contrarian, while institutional and foreign investors tend to outperform and are momentum-driven.\nThe study finds that individual investors prefer extremes in size during their portfolio selection, while institutional investors are good at forecasting mid-cap companies.\nForeign investors only focus on the KOSPI 50 companies and are good at forecasting their directions.",
    "edge": "The study provides an edge in understanding the trading patterns of different investor groups and their market impacts.\nThe findings can be used to construct profitable trading strategies based on the trading patterns of investor groups.",
    "pseudo_code": {
      "signal_generation": "Analyze the trading patterns of individual, institutional, and foreign investors. Construct a transaction portfolio based on the trading patterns of each investor group.",
      "entry_rules": "Enter the position when the transaction portfolio is constructed.",
      "exit_rules": "Liquidate the portfolio after a given holding period."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/1211.6517v1",
      "title": "Momentum universe shrinkage effect in price momentum"
    },
    "idea_name": "Investor Groups and Transaction Portfolio",
    "updated_dt": "2025-04-14T12:38:49.209356",
    "learnings_from_testing": [
      {
        "timestamp": "2025-04-14T12:53:50.385524",
        "backtest_results": "Backtest result: {'folder_path': 'Strategies/AgenticDev/ShinyGoldenOtter/backtests/2025-04-14_12-53-30', 'backtest_successful': False, 'errors': ['20250414 16:53:36.086 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.087 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.087 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.088 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.088 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.088 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.089 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.089 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.090 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.090 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.093 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.101 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.101 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.107 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.111 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.112 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.114 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.115 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.117 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.119 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.120 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.121 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.123 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.124 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.126 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.128 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.131 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.132 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.133 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.135 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.138 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.142 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.142 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.144 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.145 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.145 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.149 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.153 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.154 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.154 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.154 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.155 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.155 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.156 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.157 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.160 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.161 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.162 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.163 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.165 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.165 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.166 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.167 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.167 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.167 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.168 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.169 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.170 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.172 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.175 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.176 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String', '20250414 16:53:36.176 ERROR:: TradeBar.Reader(): Error parsing stream, Symbol: NVDA, SecurityType: Equity, Resolution: Daily, Date: 2017-11-16, Message: System.FormatException: String']}",
        "strategy_path": "Strategies/AgenticDev/ShinyGoldenOtter/strategy_v1_0_2.py"
      }
    ]
  },
  "26c10ac0-3546-4b4d-b80f-9b7311f4f771": {
    "description": "Analyzing high-frequency data of cryptocurrency markets\nIdentifying intraday trading patterns related to algorithmic trading\nStudying trading quantities such as returns, traded volumes, volatility periodicity\nProviding summary statistics of return correlations to CRIX\nInvestigating temporal aspects of high-frequency based market statistics\nFocusing on 5-minute intervals\nUsing Generalized Additive Models (GAM) to visualize intraday seasonality patterns\nModeling highly complex nonlinear relationships\nExploring large high-frequency datasets\nInvestigating intraday return volatility\nCalculating absolute log-returns\nDefining log returns as rett = log Pt/Pt-1\nExpressing intraday seasonality patterns using GAM\nIdentifying daily and weekly patterns\nObserving extreme returns and volatility",
    "edge": "Exploiting intraday momentum\nCapitalizing on mean reversion\nTaking advantage of volatility\nIdentifying market drivers\nDiversifying portfolios\nHedging against risk\nImproving trading performance",
    "pseudo_code": {
      "signal_generation": "Calculate intraday returns and volatility using GAM",
      "entry_rules": "Enter long when intraday returns are positive and volatility is high",
      "exit_rules": "Exit when intraday returns turn negative or volatility decreases"
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2009.04200v1",
      "title": "Rise of the Machines? Intraday High-Frequency Trading Patterns of Cryptocurrencies"
    },
    "idea_name": "Intraday Momentum Trading",
    "updated_dt": "2025-04-14T12:39:04.282690"
  },
  "aa99f51c-903d-4146-bf03-6bb888d51e47": {
    "description": "Hypothesizing that humans dominate cryptocurrency markets\nAnalyzing time-of-day effects\nObserving daily and weekly patterns\nIdentifying human activity curves\nNoting peak activity between 17:00 and 20:00\nDecline in activity during weekends\nContrasting with algorithmic trading patterns\nInvestigating anomalies such as the 'Monday Effect'\nApplying parametric and nonparametric methods",
    "edge": "Exploiting human behavior\nCapitalizing on market sentiment\nTaking advantage of weekend effects\nIdentifying market trends\nImproving trading performance",
    "pseudo_code": {
      "signal_generation": "Calculate time-of-day effects using GAM",
      "entry_rules": "Enter long when human activity is high",
      "exit_rules": "Exit when human activity decreases"
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2009.04200v1",
      "title": "Rise of the Machines? Intraday High-Frequency Trading Patterns of Cryptocurrencies"
    },
    "idea_name": "Proof-Of-Human Trading",
    "updated_dt": "2025-04-14T12:39:04.284495"
  },
  "4b5b3855-ac08-4f44-8035-ad42dee99cb1": {
    "description": "Evaluating the potential of portfolio allocation strategies\nInvestigating liquidity constrained investment approaches\nAnalyzing pairwise crypto-currency correlations\nIdentifying market drivers\nObserving low return correlations\nSuggesting strong diversification benefits",
    "edge": "Diversifying portfolios\nHedging against risk\nImproving trading performance\nExploiting market inefficiencies",
    "pseudo_code": {
      "signal_generation": "Calculate pairwise correlations",
      "entry_rules": "Enter long when correlations are low",
      "exit_rules": "Exit when correlations increase"
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2009.04200v1",
      "title": "Rise of the Machines? Intraday High-Frequency Trading Patterns of Cryptocurrencies"
    },
    "idea_name": "Cryptocurrency Portfolio Allocation",
    "updated_dt": "2025-04-14T12:39:04.286799"
  },
  "c8ea0f98-031f-4ec4-ad7a-97829f5d2d83": {
    "description": "This strategy uses a Proximal Policy Optimization (PPO) algorithm with an auxiliary task to improve the performance of a deep reinforcement learning agent in the forex market.\nThe auxiliary task uses an Autoencoder (AE) and K-Means algorithm to cluster the input data and provide a suitable label for each input instance.\nThe proposed model, called PPO+AXT, uses an Actor-Critic structure to monitor the trading environment and make optimal trades.\nThe agent learns to adapt to environmental conditions by predicting the input data label and comparing them with the output of the auxiliary task.\nThe PPO+AXT model has been tested on two separate datasets (DS1 and DS2) and has shown significant improvement in performance compared to the basic PPO model.\nThe performance improvement is measured using the percentage of performance improvement (PPI) criterion.\nThe results have shown that the PPO+AXT model has been able to obtain promising results compared to the agent without an auxiliary task.\nThe proposed model has shown a better average performance than the base PPO model on both datasets.\nThe PPO+AXT model uses a distributed reward function and optimizes the PPO algorithm for better execution quality.\nThe auxiliary task helps the agent learn useful features or representations of the data that can improve the agent's performance on the main task.\nThe proposed structure for creating an appropriate label for input data is called AXT.\nThe AXT network preprocesses the inputs and generates 12 new features, called golden features, from its latent.\nThe golden features are then given to the K-Means algorithm for clustering and categorizing the trading data to produce a suitable label.\nThe input data along with the created label are given to the Actor-Critic network so that the appropriate trading action is performed by the Actor network.\nThe action performed by the actor is checked by the Critic and Auxiliary Task, and based on their feedback, the network is modified to learn a more optimal policy.",
    "edge": "The use of an auxiliary task improves the learning efficiency of the agent.\nThe PPO+AXT model has shown significant improvement in performance compared to the basic PPO model.\nThe proposed model has been able to perform much better than the basic PPO model and has a significant improvement.\nThe combination of the PPO algorithm with auxiliary work is better than its combination with additional reward.\nThe proposed model has shown better performance in terms of return and sharp-ratio.",
    "pseudo_code": {
      "signal_generation": "The signal generation logic is based on the output of the Actor network, which takes the input data and the created label as inputs.",
      "entry_rules": "The entry rules are based on the trading actions (buying, selling, nothing) indicated by the Actor network.",
      "exit_rules": "The exit rules are based on the Critic network, which evaluates the performance of the Actor network and provides feedback to modify the network."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2411.01456v1",
      "title": "Improving Deep Reinforcement Learning Agent Trading Performance in Forex using Auxiliary Task"
    },
    "idea_name": "PPO+AXT: Auxiliary Task-Based Deep Reinforcement Learning for Forex Trading",
    "updated_dt": "2025-04-14T12:46:00.195495"
  },
  "6244b762-90d6-4198-9a04-26c190721b40": {
    "description": "This strategy uses a combination of statistical analysis and machine learning techniques to forecast stock market trends.\nIt involves data exploration, correlation and autocorrelation analysis, technical indicator use, application of hypothesis tests and statistical models, and use of variable selection algorithms.\nThe k-means++ clustering algorithm is used to group the mean volatility of nine major stocks in the NYSE and NasdaqGS markets.\nThe resulting clusters are used to identify relationships between stocks based on their volatility behavior.\nThe Granger Causality Test is applied to the clustered dataset with mid-volatility to determine the predictive power of a stock over another stock.\nStocks with strong predictive relationships are established as a trend indicator to determine the buy, sell, and hold of target stock trades.\nThe strategy is backtested and evaluated using various performance metrics, including total returns, Sharpe ratio, Sortino ratio, and Calmar ratio.\nThe results suggest that the approach effectively captures profitable trading opportunities by leveraging the predictive power of volatility clusters and Granger causality relationships between stocks.\nThe strategy offers valuable insights and practical implications to investors and market participants who seek to improve their trading decisions and capitalize on market trends.\nIt provides a reliable and robust method for identifying profitable pairs of stocks and predicting their trends.\nThe use of k-means++ clustering and Granger Causality Test allows for a more accurate identification of volatility regimes and predictive relationships.\nThe strategy can be applied to different markets and asset classes, including cryptocurrencies and defi-tokens.\nThe AITA framework used in this study provides a flexible and modular architecture for implementing and testing different trading strategies.\nThe results of this study can be used as a starting point for further research and development of more advanced trading strategies.",
    "edge": "The strategy provides a unique approach to identifying profitable pairs of stocks and predicting their trends.\nThe use of Granger Causality Test allows for a more accurate identification of predictive relationships between stocks.\nThe strategy can be applied to different markets and asset classes, including cryptocurrencies and defi-tokens.\nThe results of this study can be used as a starting point for further research and development of more advanced trading strategies.\nThe strategy offers valuable insights and practical implications to investors and market participants who seek to improve their trading decisions and capitalize on market trends.",
    "pseudo_code": {
      "signal_generation": "The signal generation logic involves the following steps:\n1. Calculate the historical volatility of each stock using different estimators (e.g. Parkinson, Garman-Klass, Rogers-Satchell, Yang-Zhang).\n2. Cluster the stocks into different volatility regimes using the k-means++ algorithm.\n3. Apply the Granger Causality Test to the clustered dataset to identify predictive relationships between stocks.\n4. Use the predictive relationships to generate buy and sell signals for each stock.",
      "entry_rules": "The entry rules for a long position are:\n1. The stock is in a low volatility regime.\n2. The predictive relationship between the stock and another stock in a higher volatility regime is significant.\n3. The price of the stock is above its moving average.",
      "exit_rules": "The exit rules for a long position are:\n1. The stock is in a high volatility regime.\n2. The predictive relationship between the stock and another stock in a lower volatility regime is no longer significant.\n3. The price of the stock is below its moving average."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2307.13422v2",
      "title": "VolTS: A Volatility-based Trading System to forecast Stock Markets Trend using Statistics and Machine Learning"
    },
    "idea_name": "Volatility-based Trading System using Granger Causality Test",
    "updated_dt": "2025-04-14T12:46:11.795618"
  },
  "ffa503d4-7eea-4438-9488-6dfd6d2370d8": {
    "description": "This approach involves using machine learning to predict the risk/reward ratio of trades.\nIt combines direction prediction and price prediction models.\nThe direction prediction model forecasts market direction.\nThe price prediction model estimates potential profits and losses.\nThe risk/reward ratio is used to optimize trade size using Kelly's formula.\nThe approach is tested on Bitcoin hourly OHLCV data.\nThe dataset spans from February 2017 to June 2023.\nTechnical indicators such as TRIX, MACD, and RSI are used as features.\nThe models are trained and validated using various metrics.\nThe approach is compared to benchmark strategies.\nThe results show improved risk-adjusted returns.\nThe approach can be applied to various markets and time frames.\nIt provides a pragmatic trading approach with potential for improvement.\nThe use of Kelly's formula allows for optimal trade sizing.\nThe approach can be further optimized using alternative risk management techniques.",
    "edge": "Improved risk-adjusted returns\nOptimal trade sizing using Kelly's formula\nCombining direction and price prediction models\nUsing technical indicators as features\nApplicability to various markets and time frames",
    "pseudo_code": {
      "signal_generation": "Generate direction prediction and price prediction signals using XGBoost and regression models",
      "entry_rules": "Enter long position when direction prediction signal is 1 and price prediction signal is positive, enter short position when direction prediction signal is -1 and price prediction signal is negative",
      "exit_rules": "Exit position when risk/reward ratio reaches a predetermined threshold"
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2311.09148v1",
      "title": "Predicting risk/reward ratio in financial markets for asset management using machine learning"
    },
    "idea_name": "Risk/Reward Ratio Prediction using Machine Learning",
    "updated_dt": "2025-04-14T12:46:27.012218"
  },
  "250b20f1-ca8e-489a-a8e6-06ae5b95b940": {
    "description": "This approach involves using triple barrier labeling to define profit and loss limits.\nIt uses machine learning to predict market direction and price movements.\nThe approach is tested on Bitcoin hourly OHLCV data.\nThe dataset spans from February 2017 to June 2023.\nTechnical indicators such as TRIX, MACD, and RSI are used as features.\nThe models are trained and validated using various metrics.\nThe approach is compared to benchmark strategies.\nThe results show improved risk-adjusted returns.\nThe approach can be applied to various markets and time frames.\nIt provides a pragmatic trading approach with potential for improvement.\nThe use of triple barrier labeling allows for clear definition of profit and loss limits.\nThe approach can be further optimized using alternative risk management techniques.",
    "edge": "Improved risk-adjusted returns\nClear definition of profit and loss limits\nApplicability to various markets and time frames\nUsing technical indicators as features\nCombining machine learning with triple barrier labeling",
    "pseudo_code": {
      "signal_generation": "Generate signals using triple barrier labeling and machine learning models",
      "entry_rules": "Enter long position when signal is 1, enter short position when signal is -1",
      "exit_rules": "Exit position when profit or loss limit is reached"
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2311.09148v1",
      "title": "Predicting risk/reward ratio in financial markets for asset management using machine learning"
    },
    "idea_name": "Triple Barrier Labeling with Machine Learning",
    "updated_dt": "2025-04-14T12:46:27.013558"
  },
  "87f8480d-f967-40b3-bf22-6f92afc34fe2": {
    "description": "This approach involves using Kelly's formula to optimize trade size.\nIt uses predicted probabilities and price movements to estimate potential profits and losses.\nThe approach is tested on Bitcoin hourly OHLCV data.\nThe dataset spans from February 2017 to June 2023.\nTechnical indicators such as TRIX, MACD, and RSI are used as features.\nThe models are trained and validated using various metrics.\nThe approach is compared to benchmark strategies.\nThe results show improved risk-adjusted returns.\nThe approach can be applied to various markets and time frames.\nIt provides a pragmatic trading approach with potential for improvement.\nThe use of Kelly's formula allows for optimal trade sizing.\nThe approach can be further optimized using alternative risk management techniques.",
    "edge": "Improved risk-adjusted returns\nOptimal trade sizing using Kelly's formula\nApplicability to various markets and time frames\nUsing technical indicators as features\nCombining predicted probabilities with price movements",
    "pseudo_code": {
      "signal_generation": "Generate signals using predicted probabilities and price movements",
      "entry_rules": "Enter long position when predicted probability is high and price movement is positive, enter short position when predicted probability is low and price movement is negative",
      "exit_rules": "Exit position when risk/reward ratio reaches a predetermined threshold"
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2311.09148v1",
      "title": "Predicting risk/reward ratio in financial markets for asset management using machine learning"
    },
    "idea_name": "Kelly Criterion-based Trading Strategy",
    "updated_dt": "2025-04-14T12:46:27.014547",
    "learnings_from_testing": [
      {
        "timestamp": "2025-04-15T13:23:50.976206",
        "backtest_results": "Backtest result: {'folder_path': 'Strategies/AgenticDev/QuietBrownBear/backtests/2025-04-15_13-23-45', 'backtest_successful': False, 'errors': ['/crypto/coinbase/hour/btcusd_trade.zip', '/crypto/coinbase/hour/btcusd_trade.zip', '/crypto/coinbase/hour/btcusd_quote.zip', '/crypto/coinbase/hour/btcusd_trade.zip', '/crypto/coinbase/hour/btcusd_quote.zip']}",
        "strategy_path": "Strategies/AgenticDev/QuietBrownBear/strategy_v1_0_2.py"
      }
    ]
  },
  "d8dfdb0a-12dc-4d8a-947b-5b038a23b32a": {
    "description": "This strategy is based on the principle of mean reversion using the Internal Bar Strength (IBS) indicator.\nIt operates on a basket of country-specific ETFs.\nThe core idea is to identify the ETFs experiencing the most extreme intraday price movements relative to their daily range.\nCalculate the daily IBS for each ETF in the selected basket.\nIBS formula: IBS = (Close - Low) / (High - Low).\nIBS values range from 0 (close at the low) to 1 (close at the high).\nIdentify the ETF with the minimum IBS value within the basket for the current day.\nIdentify the ETF with the maximum IBS value within the basket for the current day.\nA very low IBS (near 0) suggests the ETF closed near its low and might be oversold, potentially reversing upwards.\nA very high IBS (near 1) suggests the ETF closed near its high and might be overbought, potentially reversing downwards.\nThe strategy goes long the ETF with the minimum IBS.\nSimultaneously, the strategy goes short the ETF with the maximum IBS.\nThis creates a market-neutral or partially hedged position.\nTrades are entered at or very close to the market close on the day the IBS is calculated (Day t).\nPositions are held for exactly one trading day.\nPositions are exited at or very close to the market close on the next trading day (Day t+1).\nThe strategy is designed to be 'always in' the market, holding one long and one short position daily from the basket.\nPerformance tends to improve as the size of the ETF basket increases.\nLarger baskets increase the probability of finding ETFs with truly extreme IBS values (closer to 0 and 1).\nThe strategy was tested on a basket including ETFs like PIN, FXI, EWI, EWW, EZA, EWT, EWJ, IVV, EWU, EZU, EWA, EWS, EWC, EIS, EWZ.\nThe paper suggests mixed baskets (Emerging + Developed markets) perform better than purely EM or DM baskets.\nRequires daily calculation of IBS and rebalancing of the long/short pair.",
    "edge": "Captures short-term mean reversion tendencies following extreme intraday price movements.\nProvides diversification by selecting from a basket of uncorrelated or semi-correlated country ETFs.\nThe paired long/short structure provides a hedge against broad market movements.\nBeing 'always in' maximizes exposure to the potential mean-reversion effect compared to threshold strategies.\nSystematic and quantitative approach, removing emotional decision-making.\nDemonstrated strong historical performance (Sharpe Ratios up to ~3.9 in specific baskets according to the paper, before costs).\nExploits the finding that daily IBS is a strong predictor of next-day close-to-close returns.\nIncreased signal reliability in larger baskets due to higher likelihood of extreme IBS values.",
    "pseudo_code": {
      "signal_generation": "1. Define a basket of country ETFs (e.g., 10-15 ETFs).\n2. At the end of trading day 't', for each ETF in the basket:\n   a. Get Daily High (H), Low (L), Close (C).\n   b. Calculate IBS = (C - L) / (H - L).\n3. Identify ETF_min_IBS with the minimum IBS value in the basket.\n4. Identify ETF_max_IBS with the maximum IBS value in the basket.",
      "entry_rules": "1. At or very near the close of day 't':\n   a. Place a market-on-close order to Buy ETF_min_IBS.\n   b. Place a market-on-close order to Sell Short ETF_max_IBS.\n2. Allocate equal capital (or maintain dollar neutrality) to the long and short positions.",
      "exit_rules": "1. At or very near the close of the next trading day ('t+1'):\n   a. Place a market-on-close order to Sell the long position in ETF_min_IBS.\n   b. Place a market-on-close order to Buy to Cover the short position in ETF_max_IBS."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2306.12434v1",
      "title": "Using Internal Bar Strength as a Key Indicator for Trading Country ETFs"
    },
    "idea_name": "IBS Min-Max Country ETF Pairs Strategy",
    "updated_dt": "2025-04-15T12:51:28.079974"
  },
  "46a1601f-26d2-48d8-bd20-49ee5d07e2b5": {
    "description": "This is a modification of the Min-Max strategy, designed to further enhance diversification.\nIt also operates on a basket of country-specific ETFs using the daily IBS indicator.\nCalculate the daily IBS for each ETF in the selected basket at the close.\nIBS formula: IBS = (Close - Low) / (High - Low).\nSort all ETFs in the basket based on their calculated IBS values in ascending order.\nDefine 'N' as the number of ETFs to trade on each side (long and short).\nSelect the 'N' ETFs with the lowest IBS values (bottom N).\nSelect the 'N' ETFs with the highest IBS values (top N).\nLow IBS suggests potential upward reversal; high IBS suggests potential downward reversal.\nThe strategy goes long the bottom N ETFs.\nSimultaneously, the strategy goes short the top N ETFs.\nThis creates a portfolio of N long positions and N short positions.\nThe total position aims for market neutrality or reduced directional risk.\nTrades are entered at or very close to the market close on the day the IBS is calculated (Day t).\nPositions are held for exactly one trading day.\nPositions are exited at or very close to the market close on the next trading day (Day t+1).\nThe paper found that increasing 'N' generally increased the Sharpe ratio (tested up to N=4 or more in Fig 6).\nThis strategy hedges against idiosyncratic risk in any single ETF performing contrary to the IBS signal.\nAveraging returns across multiple long and short positions can lead to smoother equity curves.\nRequires daily calculation, sorting, and rebalancing of 2*N positions.\nTested on the same set of country ETFs as the Min-Max strategy.\nThe choice of 'N' can be optimized based on transaction costs, liquidity, and desired diversification level.\nImplicitly assumes sufficient capital to trade 2*N positions simultaneously.",
    "edge": "Enhanced diversification compared to the single pair Min-Max strategy.\nReduced impact of any single ETF failing to mean revert as expected.\nPotentially smoother equity curve due to averaging effects across multiple positions.\nCaptures a broader range of mean-reversion opportunities within the basket each day.\nSystematic selection of multiple long/short candidates based on quantitative IBS ranking.\nShown to improve Sharpe Ratio as 'N' increases in the study (before costs).\nMaintains the core edge of the IBS indicator: predicting short-term reversals.\nRemains 'always in' the market, maximizing exposure to the effect.\nBenefits from larger ETF baskets providing more candidates for the top/bottom N selection.",
    "pseudo_code": {
      "signal_generation": "1. Define a basket of country ETFs and the number 'N' (e.g., N=3).\n2. At the end of trading day 't', calculate daily IBS for all ETFs in the basket.\n3. Sort ETFs by IBS value in ascending order.\n4. Identify the set 'Bottom_N_ETFs' containing the N ETFs with the lowest IBS values.\n5. Identify the set 'Top_N_ETFs' containing the N ETFs with the highest IBS values.",
      "entry_rules": "1. At or very near the close of day 't':\n   a. For each ETF in 'Bottom_N_ETFs', place a market-on-close order to Buy.\n   b. For each ETF in 'Top_N_ETFs', place a market-on-close order to Sell Short.\n2. Allocate capital appropriately across the N long and N short positions (e.g., equal weight per position).",
      "exit_rules": "1. At or very near the close of the next trading day ('t+1'):\n   a. For each ETF held long, place a market-on-close order to Sell.\n   b. For each ETF held short, place a market-on-close order to Buy to Cover."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2306.12434v1",
      "title": "Using Internal Bar Strength as a Key Indicator for Trading Country ETFs"
    },
    "idea_name": "IBS Multi-ETF Top/Bottom N Strategy",
    "updated_dt": "2025-04-15T12:51:28.084676"
  },
  "54d7cd91-4995-47cf-acbf-10d7073084ce": {
    "description": "This strategy adapts the IBS mean-reversion concept for long-only portfolios.\nIt addresses challenges related to short selling, such as borrow costs and availability.\nOperates on a basket of country-specific ETFs.\nCalculate the daily IBS for each ETF in the selected basket at the close.\nIBS formula: IBS = (Close - Low) / (High - Low).\nIdentify the ETF with the minimum IBS value within the basket for the current day.\nA very low IBS (near 0) suggests the ETF closed near its low, is potentially oversold, and may reverse upwards.\nThe strategy goes long only the ETF with the minimum IBS.\nNo short positions are taken.\nThis captures the statistically stronger long side of the IBS mean-reversion effect noted in the paper (Table 4).\nTrades are entered at or very close to the market close on the day the IBS is calculated (Day t).\nThe position is held for exactly one trading day.\nThe position is exited at or very close to the market close on the next trading day (Day t+1).\nThe strategy likely involves holding only one ETF position at a time, rotated daily based on the minimum IBS signal.\nPerformance depends on the basket composition and the frequency of strong buy signals (very low IBS).\nCan be viewed as a daily selection mechanism for a single long holding within the ETF basket.\nSimpler to implement than long/short strategies due to avoiding the short leg.\nPerformance is sensitive to overall market direction but aims to select ETFs poised for a relative bounce.\nRequires daily calculation of IBS and rebalancing of the single long position.\nPotentially lower capital requirement compared to paired or multi-ETF strategies.\nCould be modified to trade the bottom 'N' ETFs long, similar to the Top/Bottom N strategy but without the short side.\nPerformance metrics (Sharpe) for long-only versions were generally positive and sometimes high in the paper's tests (Table 4).",
    "edge": "Captures the positive mean-reversion effect observed for low IBS ETFs.\nAvoids short selling complexities, costs (borrow fees), and risks (unlimited loss potential).\nSimpler execution and potentially lower transaction costs compared to paired strategies.\nFocuses on the empirically stronger long signal from the IBS indicator as suggested by the paper.\nProvides a systematic method for daily ETF selection within a long-only mandate.\nStill benefits from diversification across the basket over time, although only one ETF is held at once.\nReduces sensitivity to high or variable ETF borrow rates.\nCan be implemented in accounts where shorting is restricted.",
    "pseudo_code": {
      "signal_generation": "1. Define a basket of country ETFs.\n2. At the end of trading day 't', calculate daily IBS for all ETFs in the basket.\n3. Identify ETF_min_IBS with the minimum IBS value in the basket.",
      "entry_rules": "1. At or very near the close of day 't':\n   a. Liquidate any existing position held from day 't-1'.\n   b. Place a market-on-close order to Buy ETF_min_IBS.",
      "exit_rules": "1. At or very near the close of the next trading day ('t+1'):\n   a. Place a market-on-close order to Sell the long position in ETF_min_IBS."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2306.12434v1",
      "title": "Using Internal Bar Strength as a Key Indicator for Trading Country ETFs"
    },
    "idea_name": "IBS Long-Only Minimum Selection Strategy",
    "updated_dt": "2025-04-15T12:51:28.087546"
  },
  "f421b912-f096-486b-b8e7-571768d61898": {
    "description": "This strategy applies fixed IBS thresholds to trigger trades within a basket of ETFs.\nIt is based on the original Pagonidis findings but applied to a portfolio.\nOperates on a basket of country-specific ETFs.\nDefine a low IBS threshold (e.g., 0.2) and a high IBS threshold (e.g., 0.8).\nCalculate the daily IBS for each ETF in the selected basket at the close.\nIBS formula: IBS = (Close - Low) / (High - Low).\nIdentify all ETFs in the basket with IBS < low threshold (potential longs).\nIdentify all ETFs in the basket with IBS > high threshold (potential shorts).\nThe paper's specific implementation note: 'The strategy does not enter a trade unless both long and short thresholds are crossed'.\nThis implies that on any given day 't', there must be at least one ETF with IBS < 0.2 AND at least one ETF with IBS > 0.8 for *any* trades to occur.\nIf the condition is met, the strategy goes long all identified potential long ETFs.\nSimultaneously, if the condition is met, the strategy goes short all identified potential short ETFs.\nIf the condition is not met (e.g., only low IBS ETFs are found, or only high IBS ETFs, or none), no trades are entered for that day.\nTrades are entered at or very close to the market close on the day the IBS is calculated (Day t).\nPositions are held for a defined period, typically one trading day as per the paper's comparisons.\nPositions are exited at or very close to the market close on the next trading day (Day t+1) or after the defined holding period.\nThis strategy is not 'always in' the market; trading frequency depends on how often the dual threshold condition is met.\nThe paper found this strategy universally underperformed the Min-Max strategy (Fig 9, Fig 10).\nThe lower time-in-market likely contributes to lower overall returns and Sharpe Ratios.\nThreshold levels (0.2, 0.8) can be optimized.\nRequires daily calculation of IBS for all ETFs and checking against thresholds.\nCould involve trading multiple long and short positions simultaneously if multiple ETFs cross thresholds on the same day.\nPotentially filters out days with weaker signals compared to Min-Max.",
    "edge": "Provides a rule-based approach using specific, predefined IBS levels.\nFilters trades, only entering when potentially strong reversal signals (both oversold and overbought conditions present in the basket) occur according to the thresholds.\nBuilds directly on the original IBS mean-reversion concept thresholds.\nSystematic and quantitative.\nMay avoid trading during periods of low volatility or when extreme conditions are not met.\nApplies signals across a basket for diversification when trades are triggered.",
    "pseudo_code": {
      "signal_generation": "1. Define a basket of country ETFs, a low IBS threshold (T_low, e.g., 0.2), and a high IBS threshold (T_high, e.g., 0.8).\n2. At the end of trading day 't', calculate daily IBS for all ETFs in the basket.\n3. Create a list 'Long_Candidates' of ETFs where IBS < T_low.\n4. Create a list 'Short_Candidates' of ETFs where IBS > T_high.\n5. Set Trade_Flag = FALSE.\n6. If 'Long_Candidates' is not empty AND 'Short_Candidates' is not empty, set Trade_Flag = TRUE.",
      "entry_rules": "1. If Trade_Flag is TRUE at the close of day 't':\n   a. For each ETF in 'Long_Candidates', place a market-on-close order to Buy.\n   b. For each ETF in 'Short_Candidates', place a market-on-close order to Sell Short.\n2. If Trade_Flag is FALSE, do not enter any new positions.",
      "exit_rules": "1. At or very near the close of the next trading day ('t+1'):\n   a. For each ETF held long from day 't', place a market-on-close order to Sell.\n   b. For each ETF held short from day 't', place a market-on-close order to Buy to Cover."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2306.12434v1",
      "title": "Using Internal Bar Strength as a Key Indicator for Trading Country ETFs"
    },
    "idea_name": "IBS Basket Threshold Mean Reversion Strategy",
    "updated_dt": "2025-04-15T12:51:28.089959"
  },
  "511d2cd0-bd52-49b5-9e1a-b822bbda5f29": {
    "description": "IBS is a technical indicator measuring the position of the closing price relative to the high-low range of a specific period.\nTypically calculated on a daily basis (1-day IBS).\nFormula for 1-day IBS: IBS = (Close - Low) / (High - Low).\nCan be generalized to n-days: IBSn = (Close - Lown) / (Highn - Lown), where Lown and Highn are the lowest low and highest high over the past n days.\nThe paper primarily uses and finds success with the 1-day IBS.\nIBS produces values normalized between 0 and 1.\nA value close to 0 indicates the price closed near the low of the period's range.\nA value close to 1 indicates the price closed near the high of the period's range.\nA value of 0.5 indicates the price closed exactly in the middle of the period's range.\nIBS is primarily used as a short-term mean reversion indicator.\nLow IBS (e.g., < 0.2) suggests potential oversold conditions and a higher probability of an upward move (bounce) in the next period (day).\nHigh IBS (e.g., > 0.8) suggests potential overbought conditions and a higher probability of a downward move (pullback) in the next period (day).\nThe paper confirms these probabilities for country ETFs (Table 3), showing >50% chance of positive return next day after IBS < 0.2, and >50% chance of negative return (or <50% chance of positive) after IBS > 0.8 for many ETFs.\nThe predictive power seems strongest for the next day's close-to-close return.\nEffectiveness diminishes significantly for holding periods longer than 1 day (Fig 7).\nUsing IBS calculated over longer periods (e.g., 2 days) also showed weaker performance than 1-day IBS (Fig 8).\nThe indicator's value is realized most effectively when trades are entered near the close of the day the IBS is calculated.\nOpen-to-Open strategies based on the previous day's IBS perform poorly (Table 5), highlighting the importance of capturing the closing price context.\nCan be applied to various asset classes, but the paper focuses on country ETFs.\nIts calculation is simple, requiring only daily Open (optional), High, Low, and Close data.\nDistribution of IBS values tends to be heavy-tailed, with values often clustering near 0 and 1 (Fig 1).",
    "edge": "Provides a quantified measure of intraday price momentum and closing position.\nActs as a short-term predictor of mean reversion in equity ETFs.\nSimple to calculate and implement in trading systems.\nStatistically validated predictive power for next-day returns in the studied universe.\nCan be used to rank securities within a universe based on potential for short-term reversal.\nForms the basis for several systematic strategies (Min-Max, Threshold, Top/Bottom N).\nDoes not require complex modeling or external data sources beyond price.\nIdentifies potentially overbought/oversold conditions based purely on price action within the bar.",
    "pseudo_code": {
      "signal_generation": "1. Input: Daily High (H), Low (L), Close (C) for an asset.\n2. Calculate: IBS = (C - L) / (H - L)\n3. Interpretation:\n   - If IBS is low (e.g., < 0.2): Generate potential 'Buy' / 'Reversal Up' signal for next period.\n   - If IBS is high (e.g., > 0.8): Generate potential 'Sell' / 'Reversal Down' signal for next period.\n   - If IBS is mid-range (e.g., 0.2 to 0.8): Signal is neutral or weak.",
      "entry_rules": "Specific entry rules depend on the strategy employing the IBS indicator (e.g., enter at close based on Min/Max IBS within a basket, or if IBS crosses a threshold).",
      "exit_rules": "Specific exit rules depend on the strategy (e.g., exit at next close for 1-day holding period strategies)."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2306.12434v1",
      "title": "Using Internal Bar Strength as a Key Indicator for Trading Country ETFs"
    },
    "idea_name": "Internal Bar Strength (IBS) Mean Reversion Indicator",
    "updated_dt": "2025-04-15T12:51:28.091594"
  },
  "ce2cb927-c603-4d5c-adf8-6ac9f0a3d328": {
    "description": "Based on a discrete-time, two-period recombining binomial model for the underlying asset price.\nAssumes a specific structure: S0 -> {S+, S-} -> {S++, S+-, S--}, where S+- is reached from both S+ and S-.\nThe model has four possible final states (paths): \u03c91 (up-up), \u03c92 (up-down), \u03c93 (down-up), \u03c94 (down-down).\nA trading strategy \u03c6 is defined by holdings at time 0 (\u03c61) and time 1 (\u03c6+2 if S1=S+, \u03c6-2 if S1=S-).\nThe strategy has zero initial cost.\nStatistical Arbitrage (SA) requires the expected terminal value E[VT] > 0.\nSA also requires the conditional expected terminal value to be non-negative in each *final* state, E[VT | ST] \u2265 0.\nIn this specific model, the conditions simplify due to path recombination.\nCondition 1: Payoff in state \u03c91 must be non-negative: \u03c61*\u0394S1(\u03c91) + \u03c6+2*\u0394S2(\u03c91) \u2265 0.\nCondition 2: Payoff in state \u03c94 must be non-negative: \u03c61*\u0394S1(\u03c94) + \u03c6-2*\u0394S2(\u03c94) \u2265 0.\nCondition 3: Average payoff in the combined state {\u03c92, \u03c93} (where S2=S+-) must be non-negative: [\u03c61*\u0394S1(\u03c92) + \u03c6+2*\u0394S2(\u03c92)]*P(\u03c92) + [\u03c61*\u0394S1(\u03c93) + \u03c6-2*\u0394S2(\u03c93)]*P(\u03c93) \u2265 0.\nAt least one of the above inequalities must be strict for a statistical arbitrage to exist.\nThe existence of SA is linked to the ratio of physical path probabilities q = P(\u03c92) / P(\u03c93).\nSA exists if and only if q is not equal to a critical value ~q derived from the asset price dynamics (Eq. 19).\nThe critical value ~q represents the ratio q implied by the unique equivalent martingale measure in this model.\nIf q != ~q, the physical probabilities deviate from risk-neutral implied probabilities in a way that allows for SA.\nThe strategy vector \u03c6 = (\u03c61, \u03c6+2, \u03c6-2) can be explicitly calculated if SA exists (Lemma 3.7).\nThe calculation involves inverting a 3x3 matrix A (Eq. 16) derived from the SA conditions and price changes.\nThis strategy is theoretical for a pure binomial world but forms the basis for embedded strategies.",
    "edge": "Exploits discrepancies between physical probabilities (P) and risk-neutral probabilities (Q) in a simple binomial setting.\nSpecifically targets situations where the ratio of probabilities for reaching the middle state S+- via different paths (P(\u03c92)/P(\u03c93)) differs from the ratio implied by no-arbitrage (~q).\nProvides positive expected profit under the physical measure P.\nGuarantees non-negative expected profit conditional on each final *price level* (S++, S+-, S--), although losses are possible on individual paths (e.g., \u03c93).\nLeverages the structure of the binomial model to construct an explicit profitable strategy when the condition (q != ~q) holds.",
    "pseudo_code": {
      "signal_generation": "Inputs: Binomial model parameters (S0, S+, S-, S++, S+-, S--), Path probabilities P(\u03c91) to P(\u03c94).\n1. Calculate price changes: \u0394S1(path), \u0394S2(path).\n2. Calculate physical probability ratio: q = P(\u03c92) / P(\u03c93).\n3. Calculate the critical ratio ~q based on price changes (Eq. 19).\n4. Generate Signal: If q != ~q, then a statistical arbitrage opportunity exists.",
      "entry_rules": "If Signal == TRUE:\n1. Calculate the matrix A (Eq. 16).\n2. Calculate the strategy vector \u03c6 = (\u03c61, \u03c6+2, \u03c6-2) = A^-1 * [k1, k2, k3]^T (where k1, k2, k3 are small positive constants, e.g., 1, as per Lemma 3.7 proof).\n3. At time t=0, establish position: Hold \u03c61 units of the asset.",
      "exit_rules": "1. At time t=1:\n   - If S1 = S+, adjust position to hold \u03c6+2 units.\n   - If S1 = S-, adjust position to hold \u03c6-2 units.\n2. At time t=2 (end of period):\n   - Liquidate the entire position (holding \u03c6+2 or \u03c6-2).\n   - Realize the terminal value VT = \u03c61*\u0394S1 + \u03c62*\u0394S2."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/1907.09218v2",
      "title": "Generalized statistical arbitrage concepts and related gain strategies"
    },
    "idea_name": "Two-Period Binomial Statistical Arbitrage",
    "updated_dt": "2025-04-15T12:53:02.920779"
  },
  "b7ddeb3c-c8dc-48e8-a986-548d0c068b1a": {
    "description": "Applies the Two-Period Binomial SA concept to a continuous-time model (e.g., Geometric Brownian Motion).\nDoes not require the underlying process to be truly binomial.\nUses hitting times of pre-defined barriers to simulate binomial steps.\nDefine barriers around the current price Si_0 at time ti_0: Upper U1 = Si_0*(1+c), Lower L1 = Si_0*(1-c).\nDefine outer barriers: U2 = Si_0*(1+2c), L2 = Si_0*(1-2c).\nThe barrier width 'c' is a key parameter, potentially linked to \u00b5 and \u03c3 (e.g., c = 0.01 * \u00b5/\u03c3).\nFirst stopping time ti_1: The first time t > ti_0 when St hits either U1 or L1.\nSecond stopping time ti_2: The first time t > ti_1 when St hits U2 (if Sti_1=U1), L2 (if Sti_1=L1), or returns to Si_0.\nThis sequence (ti_0, ti_1, ti_2) defines one 'embedded binomial' cycle.\nThe core idea is to apply the discrete binomial SA strategy \u03c6 (from Lemma 3.7) at these stopping times.\nCalculate the effective path probabilities P(\u03c92) and P(\u03c93) for the embedded model using first passage time formulas for the continuous process (Eq. 28).\nCalculate the ratio q = P(\u03c92) / P(\u03c93) for the embedded model (Eq. 29).\nFor the GBM case with symmetric barriers \u00b1c, \u00b12c, the equivalent risk-neutral ratio ~q is 1.\nCheck if q != 1. If true, an embedded SA opportunity exists.\nCalculate the specific strategy weights \u03c61, \u03c6+2, \u03c6-2 using formulas derived from Lemma 3.7 adapted for the GBM hitting probabilities (Eqs 30-32).\nThe strategy is executed iteratively: upon reaching ti_2, the position is closed, the cycle ends, and a new cycle starts with ti+1_0 = ti_2 and Si+1_0 = Sti_2.\nThe process repeats until a final time horizon T is reached.\nThe relevant information system G is generated by the states/outcomes at the stopping times ti_2 of each cycle.\nPerformance is sensitive to the choice of 'c', drift \u00b5, and volatility \u03c3.\nSmaller 'c' leads to more frequent trading, potentially higher average gains but also higher variance and risk (Table 2).\nHigher volatility \u03c3 tends to increase average gains (Table 4), likely due to more frequent trading cycles.\nHigher drift \u00b5 (relative to \u03c3) surprisingly tends to decrease average gains in simulations (Table 3).",
    "edge": "Exploits deviations between actual hitting time probabilities in a continuous process and those implied by a simple risk-neutral random walk (~q=1 for symmetric barriers).\nTranslates a theoretical discrete-time arbitrage into an applicable continuous-time strategy.\nLeverages the law of large numbers: profits are expected on average over many repeated trading cycles.\nProvides a systematic way to trade based on short-term price movements hitting specific barriers.\nDoes not rely on forecasting long-term direction but rather on statistical properties of path segments.\nParameter 'c' allows tuning the strategy's frequency, risk, and reward profile.",
    "pseudo_code": {
      "signal_generation": "Inputs: Current price S_current, Estimated parameters \u00b5, \u03c3, Barrier parameter c.\n1. Calculate hitting probabilities for the embedded binomial model using first passage time formulas (Eq. 28) based on S_current, \u00b5, \u03c3, c.\n2. Determine P(\u03c92) (e.g., path S_current -> S_current*(1+c) -> S_current) and P(\u03c93) (e.g., path S_current -> S_current*(1-c) -> S_current).\n3. Calculate q = P(\u03c92) / P(\u03c93) (Eq. 29).\n4. Generate Signal: If q != 1 (or more generally, q != ~q), then an embedded SA opportunity exists.",
      "entry_rules": "Initialize: t_current = 0, S_start = S0.\nLoop until t_current >= T:\n  If Signal == TRUE (re-evaluate signal based on S_start, \u00b5, \u03c3):\n    1. Calculate strategy weights \u03c6 = (\u03c61, \u03c6+2, \u03c6-2) using Eqs 30-32 based on q and c*S_start.\n    2. t0 = t_current\n    3. S0_cycle = S_start\n    4. Define barriers: U1=S0_cycle*(1+c), L1=S0_cycle*(1-c), U2=S0_cycle*(1+2c), L2=S0_cycle*(1-2c).\n    5. Entry: At time t0, establish position: Hold \u03c61 units of the asset.",
      "exit_rules": "Within an active cycle:\n1. Wait for St to hit U1 or L1. Let this time be t1.\n2. At time t1:\n   - If St1 = U1, adjust position to hold \u03c6+2 units.\n   - If St1 = L1, adjust position to hold \u03c6-2 units.\n3. Wait for St to hit U2 (if St1=U1), L2 (if St1=L1), or S0_cycle. Let this time be t2.\n4. At time t2:\n   - Liquidate the entire position.\n   - Record profit/loss for the cycle.\n   - Update t_current = t2\n   - Update S_start = St2\n   - Go back to the start of the Loop to begin the next cycle."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/1907.09218v2",
      "title": "Generalized statistical arbitrage concepts and related gain strategies"
    },
    "idea_name": "Hitting-Time Embedded Binomial Arbitrage",
    "updated_dt": "2025-04-15T12:53:02.928928"
  },
  "ffba8010-fe64-4c50-bf3c-98ed0802c095": {
    "description": "An extension of the Embedded Binomial strategy designed to potentially capitalize on detected trends.\nIntroduces a third step into the embedded model structure.\nUses a similar barrier system based on parameter 'c'.\nDefine stopping times \u03c4_i^0, \u03c4_i^1, \u03c4_i^2, \u03c4_i^3 iteratively.\n\u03c4_i^1: First time price hits Si_0*(1+c) or Si_0*(1-c) (Eq 33).\n\u03c4_i^2: Dependent on state at \u03c4_i^1. If Sti_1 = Si_0*(1+c), it's the first time hitting Si_0*(1+2c) or Si_0. If Sti_1 = Si_0*(1-c), it's the first time hitting Si_0*(1-2c) or Si_0 (Eq 34).\nTrend Detection: If the process reaches Si_0*(1+2c) at time \u03c4_i^2 (for positive trend focus), an upward trend is assumed.\n\u03c4_i^3: Only relevant if trend is detected at \u03c4_i^2. Defined as the first time hitting Si_0*(1+4c) or returning to Si_0 (Eq 35). If no trend detected at \u03c4_i^2, then \u03c4_i^3 = \u03c4_i^2.\nThe strategy involves adjusting positions at \u03c4_i^1 and \u03c4_i^2, and potentially holding a trend position until \u03c4_i^3.\nUses a modified strategy vector \u03c8 = (\u03c81, \u03c8+2, \u03c8-2, \u03c8++3) based on the underlying binomial SA weights \u03c6 and an adjustment parameter \u03b1 (Prop 5.2).\n\u03c81 is held from \u03c4_i^0 to \u03c4_i^1.\n\u03c8+2 (or \u03c8-2) is held from \u03c4_i^1 to \u03c4_i^2.\nIf trend detected at \u03c4_i^2 (e.g., hit Si_0*(1+2c)), hold \u03c8++3 from \u03c4_i^2 to \u03c4_i^3.\nIf no trend detected at \u03c4_i^2 (e.g., returned to Si_0 or hit Si_0*(1-2c)), liquidate position at \u03c4_i^2.\nIf trend position was held, liquidate at \u03c4_i^3.\nThe strategy can be adapted for detecting and exploiting downward trends similarly.\nThe choice \u03b1 \u2265 0 allows tuning the trend-following component. \u03b1=1 reduces it to the standard embedded binomial strategy.\nThe relevant information system G is generated by the final states of this extended 3-step embedded model (Eq 36).\nSimulations suggest this strategy might offer lower risk (e.g., lower VaR) compared to the simple embedded binomial, often at the cost of slightly lower average gains (Table 5).\nIt may perform better when volatility is very low, allowing trends to persist (Table 8).",
    "edge": "Combines the statistical arbitrage edge from barrier hitting probabilities with a momentum/trend-following component.\nAttempts to profit more significantly if a short-term directional trend establishes after initial barrier breaks.\nProvides a structured way to participate in trends while being rooted in the statistical arbitrage framework.\nMay reduce risk compared to the simpler embedded binomial strategy by liquidating earlier if the expected trend fails to materialize (i.e., price reverts to Si_0).\nAdaptable to both upward and downward trend detection.\nOffers flexibility through the parameter \u03b1 to control the aggressiveness of the trend-following part.",
    "pseudo_code": {
      "signal_generation": "Inputs: Current price S_current, Estimated parameters \u00b5, \u03c3, Barrier parameter c, Trend adjustment \u03b1.\n1. Calculate hitting probabilities for the underlying two-period embedded binomial model (as in Idea 2) to get q.\n2. Generate Signal: If q != 1 (or ~q), an embedded SA opportunity exists.\n3. Calculate base strategy weights \u03c6 = (\u03c61, \u03c6+2, \u03c6-2) using Eqs 30-32.\n4. Calculate the full strategy weights \u03c8 = (\u03c81, \u03c8+2, \u03c8-2, \u03c8++3) using Proposition 5.2 (requires calculating auxiliary vector \u03b3 from Eq 37 and using \u03b1).",
      "entry_rules": "Initialize: t_current = 0, S_start = S0.\nLoop until t_current >= T:\n  If Signal == TRUE:\n    1. Calculate strategy weights \u03c8 based on S_start, \u00b5, \u03c3, c, \u03b1.\n    2. t0 = t_current\n    3. S0_cycle = S_start\n    4. Define barriers: B_p1=S0_cycle*(1+c), B_n1=S0_cycle*(1-c), B_p2=S0_cycle*(1+2c), B_n2=S0_cycle*(1-2c), B_p4=S0_cycle*(1+4c).\n    5. Entry: At time t0, establish position: Hold \u03c81 units.",
      "exit_rules": "Within an active cycle:\n1. Wait for St to hit B_p1 or B_n1. Let time be \u03c41.\n2. At time \u03c41:\n   - If St1 = B_p1, adjust position to hold \u03c8+2 units. State = UP1.\n   - If St1 = B_n1, adjust position to hold \u03c8-2 units. State = DOWN1.\n3. Wait for next hit based on State:\n   - If State == UP1, wait for St to hit B_p2 or S0_cycle. Let time be \u03c42.\n   - If State == DOWN1, wait for St to hit B_n2 or S0_cycle. Let time be \u03c42.\n4. At time \u03c42:\n   - If St2 = B_p2 (trend confirmed up):\n     - Adjust position to hold \u03c8++3 units.\n     - Wait for St to hit B_p4 or S0_cycle. Let time be \u03c43.\n     - At time \u03c43: Liquidate position. End Cycle.\n   - Else (St2 = S0_cycle or St2 = B_n2):\n     - Liquidate position. End Cycle.\n5. Update t_current = \u03c4_end_cycle\n6. Update S_start = S_\u03c4_end_cycle\n7. Go back to start of Loop.\n(Note: Adapt logic for negative trend detection/exploitation as described in Section 6)."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/1907.09218v2",
      "title": "Generalized statistical arbitrage concepts and related gain strategies"
    },
    "idea_name": "Follow-the-Trend Embedded Arbitrage",
    "updated_dt": "2025-04-15T12:53:02.931386"
  },
  "9f9b551c-7673-4288-8ed7-ee2734d84bde": {
    "description": "A variation of statistical arbitrage focusing on profitability conditional on broader market scenarios.\nSpecifically uses the information system G_fin generated by {ST \u2265 S0} and {ST < S0}.\nThe goal is to construct a strategy with positive overall expected profit E[VT] > 0.\nAdditionally, it requires non-negative expected profit conditional on the final price being above the initial price: E[VT | ST \u2265 S0] \u2265 0.\nAnd non-negative expected profit conditional on the final price being below the initial price: E[VT | ST < S0] \u2265 0.\nThe paper implements this concept using the structure of the Follow-the-Trend model (Section 5.3).\nIt uses the same iterative barrier-hitting approach with stopping times \u03c41, \u03c42, \u03c43.\nThe key difference lies in how the strategy weights \u03c8 = (\u03c81, \u03c8+2, \u03c8-2, \u03c8++3 / \u03c8--3) are calculated.\nThe weights must satisfy the G_fin conditions (Prop 5.3 for positive drift, Prop 6.1 for negative drift).\nExample 5.4 provides an explicit method to calculate weights assuming positive drift and invertibility of a modified matrix A.\nExample 6.2 provides the calculation method assuming negative drift.\nThese calculations ensure the average profitability across the final up/down partition.\nRemark 5.5 offers an alternative calculation under specific assumptions.\nThe strategy adapts dynamically based on estimated drift (\u00b5). If estimated \u00b5 > 0, use positive drift strategy (Ex 5.4); if \u00b5 < 0, use negative drift strategy (Ex 6.2).\nParameter estimation (\u00b5, \u03c3) can be done using a rolling window of historical data (e.g., 3 years).\nBarrier parameter 'c' remains crucial for tuning performance.\nSimulation results (Tables 9-12) show performance characteristics often similar to the Follow-the-Trend strategy.\nApplied successfully to historical stock data (Kellogg, Deutsche Bank) using rolling parameter estimates (Table 13).",
    "edge": "Targets profitability averaged over economically intuitive final outcomes (price up vs. down).\nMay be more robust than path-dependent strategies if exact path probabilities are noisy or difficult to estimate.\nProvides positive expected profit under the physical measure.\nEnsures non-negative expected profit conditional on the broader scenarios of market finishing up or down relative to the start.\nCombines the barrier-hitting mechanism with a focus on these aggregate final states.\nDemonstrated applicability to real market data with dynamic parameter estimation.\nAdapts its structure (positive/negative trend focus) based on estimated market drift.",
    "pseudo_code": {
      "signal_generation": "Inputs: Current price S_current, Historical data window for estimation, Barrier parameter c, Trend adjustment \u03b1.\n1. Estimate \u00b5 and \u03c3 from the historical data window (e.g., MLE).\n2. Determine drift direction: If estimated \u00b5 > 0, use Positive Drift logic. If estimated \u00b5 < 0, use Negative Drift logic.\n3. Calculate relevant path probabilities P(\u03c9i) for the chosen drift logic (using first passage times).\n4. Generate Signal: Check if the conditions for G_fin-arbitrage hold (invertibility of matrix A in Ex 5.4 or 6.2 implies potential). The core signal is the existence of a valid trading structure.",
      "entry_rules": "Initialize: t_current = 0, S_start = S0.\nLoop until t_current >= T:\n  1. Estimate \u00b5, \u03c3 based on recent data.\n  2. Select Positive Drift (PD) or Negative Drift (ND) logic based on \u00b5 sign.\n  3. Calculate strategy weights \u03c8 = (\u03c81, \u03c8+2/\u03c8+, \u03c8-2/\u03c8-, \u03c8++3/\u03c8--3) using the method from Example 5.4 (PD) or Example 6.2 (ND), ensuring G_fin conditions are targeted.\n  4. t0 = t_current\n  5. S0_cycle = S_start\n  6. Define barriers based on c and S0_cycle (adapt barriers/steps slightly based on PD/ND model structure, e.g. Fig 8 vs Fig 9).\n  7. Entry: At time t0, establish position: Hold \u03c81 units.",
      "exit_rules": "Within an active cycle (adapt based on PD/ND logic):\n1. Wait for first barrier hit (\u03c41).\n2. Adjust position based on which barrier was hit (\u03c8+2/\u03c8+ or \u03c8-2/\u03c8-).\n3. Wait for second barrier hit (\u03c42).\n4. At time \u03c42:\n   - If trend confirmed (e.g., hit B_p2 in PD, B_n2 in ND):\n     - Adjust position to trend-following weight (\u03c8++3 / \u03c8--3).\n     - Wait for third barrier hit (\u03c43).\n     - At time \u03c43: Liquidate position. End Cycle.\n   - Else (trend not confirmed, e.g., returned to S0_cycle):\n     - Liquidate position. End Cycle.\n5. Update t_current = \u03c4_end_cycle\n6. Update S_start = S_\u03c4_end_cycle\n7. Go back to start of Loop."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/1907.09218v2",
      "title": "Generalized statistical arbitrage concepts and related gain strategies"
    },
    "idea_name": "Final Value Partition Arbitrage Strategy",
    "updated_dt": "2025-04-15T12:53:02.933472"
  },
  "740ecf25-a06c-4351-a158-09d46537ebe6": {
    "description": "Identifies statistical arbitrage opportunities robust to model ambiguity using Deep Neural Networks (DNNs).\nDoes not rely on traditional pairs trading assumptions like cointegration or mean reversion.\nAims for strategies profitable across a *set* of plausible future probability measures (ambiguity set P), not just a single assumed measure.\nThe ambiguity set P is constructed data-drivenly based on historical market data.\nAn empirical probability measure (bP) is first created, assigning equal likelihood to observed historical return paths (scaled to current spot price).\nThe ambiguity set P consists of measures within a specified Wasserstein distance (\u03b5) from the empirical measure bP.\nMeasures in P are generated by perturbing the historical paths with noise (e.g., scaled Gaussian noise) ensuring the perturbations stay within the \u03b5-Wasserstein ball.\nThe strategy seeks a portfolio \u2206 whose net profit function `(\u2206\u00b7 S)n \u2212Cn(\u2206)` satisfies P-robust statistical arbitrage conditions.\nCondition 1: Conditional expected net profit given terminal prices (Stn) is non-negative under *all* measures P in the ambiguity set P.\nCondition 2: Unconditional expected net profit is strictly positive under *at least one* measure P in the ambiguity set P.\nTrading occurs over a fixed future horizon t1, ..., tn.\nTrading positions \u2206j_i at time ti are determined by DNNs taking past prices (St1, ..., Sti) as input.\nThe initial position \u2206j_0 (at time t0) is a constant vector, also optimized during training.\nExplicitly incorporates trading costs: transaction fees (per share or proportional), borrowing costs for short positions, and bid-ask spread costs.\nUses a penalization method to train the DNNs.\nThe objective is to minimize a functional representing the initial cost plus a penalty for violating the non-negative conditional profit requirement across measures in P.\nThe conditional expectation E[ . | \u03c3(Stn)] is approximated using conditional expectations on finite, randomly generated partitions (Fi) of the terminal price space.\nDNN parameters (weights, biases), initial position \u22060, and initial cash c are optimized using stochastic gradient descent (SGD) / backpropagation.\nApplicable to high-dimensional portfolios (demonstrated up to 50 assets).\nCan potentially incorporate online learning by fine-tuning the model on new data.\nInput data (stock prices) is typically normalized before feeding into the DNNs.\nThe framework aims to find the minimal cost `c` for a strategy `hc,\u2206 = c + (\u2206\u00b7 S)n \u2212Cn(\u2206)` that super-replicates a zero payoff conditionally on terminal prices, across all measures in P. A negative `c` indicates a robust arbitrage opportunity.",
    "edge": "Robustness to Model Uncertainty: Explicitly accounts for the fact that the true future data generating process is unknown, by requiring profitability over a *set* of plausible models.\nData-Driven Ambiguity Set: Avoids strong parametric assumptions by constructing the set of models (P) around observed historical data patterns, while allowing for deviations.\nHigh-Dimensional Scalability: Leverages DNNs to handle complex relationships in large portfolios (e.g., 50+ stocks) where traditional methods struggle.\nIndependence from Cointegration: Can find opportunities even when assets are not cointegrated or when such relationships break down, unlike standard pairs trading.\nCost Optimization: Integrates various trading costs directly into the optimization, leading to more realistic net profit expectations.\nNon-Linear Pattern Detection: DNNs can capture complex, non-linear dependencies and dynamics missed by linear models.\nSystematic Strategy Discovery: Provides a formal optimization framework rather than relying on heuristics or simple rules.\nPotential Adaptability: The use of DNNs and data-driven ambiguity sets allows the strategy to potentially adapt to changing market regimes, especially with online learning.\nOutperformance in Crisis/Stress Periods: The robustness property aims to provide more stable performance, potentially cutting losses or remaining profitable during market turmoil or regime shifts where simpler strategies fail.",
    "pseudo_code": {
      "signal_generation": "Signal generation is the output of the trained DNN model. Training involves:\n1. Define Historical Data Window (N days) and Trading Horizon (n days).\n2. Construct Empirical Measure bP: Sample n-day paths from N historical days, scale by St0.\n3. Define Wasserstein Radius \u03b5.\n4. Generate Ambiguity Set P: Create N_measures perturbed versions of bP by adding noise (e.g., scaled Gaussian) to paths, ensuring max perturbation < \u03b5 (Algorithm 2).\n5. Define DNN Architecture: One network (or set of parameters) for each trading step i=1 to n-1, mapping (St1,...,Sti) -> (Delta_1i, ..., Delta_di). Also define trainable initial position Delta_0 and cash c.\n6. Define Cost Functions: c_trans, c_spread, c_short.\n7. Define Penalty Function: e.g., beta(x) = max(x, 0)^2.\n8. Define Objective Function (Algorithm 4, eq 3.8): Minimize `c + k * Avg_P_in_P [ E_P[ beta( Avg_Fi [ -NetProfit(Path_under_P) * Indicator(TerminalPrice_under_P in Fi_b) / P(Fi_b) ] * Indicator(TerminalPrice_under_P in Fi_b) ) ] ]` where Fi is the random partition approximating sigma(Stn), k is penalty weight, NetProfit includes costs.\n9. Train Parameters: Use SGD/backpropagation to minimize the objective w.r.t. DNN weights/biases, Delta_0, and c, using samples from P and generated partitions Fi (Algorithm 3).",
      "entry_rules": "Entry is determined by the trained model over the n-day horizon:\n1. At t0 (start of trading period): Set initial position vector to the optimized Delta_0 = (Delta_10, ..., Delta_d0).\n2. At each subsequent trading time ti (i=1 to n-1):\n   a. Obtain current market prices up to ti: (St1, ..., Sti).\n   b. Feed these prices into the trained DNN corresponding to step ti.\n   c. The DNN output is the target position vector Delta_i = (Delta_1i, ..., Delta_di).\n   d. Calculate required trades: Trades = Delta_i - Delta_(i-1) (where Delta_(i-1) is the position held just before trading at ti).\n   e. Execute trades to reach the target position Delta_i.",
      "exit_rules": "The strategy operates over the predefined n-day horizon:\n1. At the final time tn: Liquidate all held positions (close out Delta_(n-1)).\n2. The net profit is calculated based on trades from t0 to tn and final liquidation.\n3. Re-train/Re-optimize: The entire process (signal generation/training) is typically repeated periodically (e.g., daily, weekly) using updated historical data and the new spot price St0 to determine the strategy for the *next* n-day trading window."
    },
    "source_info": {
      "url": "http://arxiv.org/pdf/2203.03179v4",
      "title": "Detecting data-driven robust statistical arbitrage strategies with deep neural networks"
    },
    "idea_name": "Deep Robust Statistical Arbitrage",
    "updated_dt": "2025-04-15T12:53:43.499889"
  }
}